{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGSCI 700 Geothermal Reservoir Optimisation\n",
    "\n",
    "This workbook is for extracting Contact well data and recreating the plots.\n",
    "\n",
    "(Unix) launch with `cd src` >`jupyter notebook`\n",
    "\n",
    "File structure: \n",
    "```\n",
    "(root)\n",
    "├── src\n",
    "│    └── Python Test.ipynb\n",
    "└── wairakei_data\n",
    "     └── Liquid wells (version 1).xlsx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from datetime import datetime, timedelta\n",
    "%matplotlib inline\n",
    "\n",
    "base_year = '2000'    # numeric dates calculated from Jan-01\n",
    "\n",
    "def datetime_to_numeric(my_datetime):\n",
    "    # returns days since base_year-01-01.\n",
    "    try:\n",
    "        date_numeric = (my_datetime - datetime(int(base_year),1,1)) / timedelta(days=1)   # datetime implem\n",
    "    except:\n",
    "        date_numeric = (my_datetime - np.datetime64(base_year)) / np.timedelta64(1, 'D')  # numpy implem\n",
    "    return date_numeric\n",
    "\n",
    "# Check if Excel file is already in memory (loading is slow)\n",
    "try:    xl\n",
    "except: xl = pd.ExcelFile('../wairakei_data/Liquid wells (version 1).xlsx')\n",
    "print([x for x in xl.sheet_names if len(x) < 6], '...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# sheets to load data from\n",
    "# wells = ['wk255', 'wk256', 'w258', 'w259']\n",
    "sheets = ['wk255']\n",
    "# wells = ['wk255', 'wk256', 'wk247', 'w267', 'w268',\n",
    "#          'w269', 'WK270', 'WK271', 'WK272']\n",
    "        # missing: wk251, wk250, wk252, wk238, wk234, wk240, wk241, wk267, wk268\n",
    "\n",
    "dfs = []\n",
    "for sheet in sheets:\n",
    "    df = xl.parse(sheet)                                       # select well data\n",
    "    df['well'] = sheet                                            # label data with well name\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# df = df.loc[:, ~df.columns.str.contains('^Unnamed|SUMMARY|slope|intercept')]     # remove extra columns\n",
    "df = df[['date', 'whp', 'mf', 'h', 'well']]                      # instead, only keep certain columns\n",
    "df['well'] = df['well'].str.lower()                              # remove 'WK' inconsistencies\n",
    "df['well'] = df['well'].str.replace(\"^[^\\d]*\", \"wk\")\n",
    "df['mf'] = pd.to_numeric(df['mf'], errors='coerce')              # remove 'dummy' entries\n",
    "df = df.dropna(subset=['date', 'whp', 'mf'])                     # remove NA\n",
    "\n",
    "df['date_numeric'] = datetime_to_numeric(df['date']) #  yrs since base_year\n",
    "df = df.reset_index()\n",
    "# save data to import into R if needed\n",
    "df.to_csv('../wairakei_data/data.csv', index=False)\n",
    "wells = df['well'].unique()\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up regression data and create prediction frame for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pred = np.arange(df['date'].min(), df['date'].max(), np.timedelta64(365*2, 'D').astype(datetime))\n",
    "date_numeric_pred = datetime_to_numeric(date_pred)\n",
    "whp_pred = np.linspace(0, 16, 1000)\n",
    "well_pred = wells\n",
    "pred = pd.DataFrame(list(itertools.product(date_numeric_pred, whp_pred, well_pred)),\n",
    "                    columns=['date_numeric', 'whp', 'well'])\n",
    "pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform regression and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Not conditioned on date\n",
    "model1 = ols(\"mf ~ well * whp\", data=df)\n",
    "results1 = model1.fit()\n",
    "pred['mf1'] = results1.predict(pred)\n",
    "\n",
    "# Linear fit dependent on date\n",
    "model2 = ols(\"mf ~ well * (whp + date_numeric)\", data=df)\n",
    "results2 = model2.fit()\n",
    "pred['mf2'] = results2.predict(pred)\n",
    "\n",
    "# Elliptic fit dependent on date\n",
    "model3 = ols(\"np.power(mf,2) ~ well * (np.power(whp,2) + date_numeric)\", data=df)\n",
    "results3 = model3.fit()\n",
    "pred['mf3^2'] = results3.predict(pred)\n",
    "pred.loc[pred['mf3^2'] < 0, 'mf3^2'] = np.nan    # remove invalid results\n",
    "pred['mf3'] = np.sqrt(pred['mf3^2'])\n",
    "\n",
    "pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "# ===============================================================\n",
    "# Set up axes\n",
    "# ===============================================================\n",
    "\n",
    "# colors\n",
    "cmap = plt.get_cmap('viridis')\n",
    "indices = np.linspace(0, cmap.N, len(df))\n",
    "my_colors = [cmap(int(i)) for i in indices]\n",
    "\n",
    "# subplots\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=[14,4], gridspec_kw={'width_ratios': [9,9,9,1]})\n",
    "ax1.get_shared_y_axes().join(ax1, ax2, ax3)\n",
    "ax1.set_ylim([0, 1000])\n",
    "ax1.set_xlim(0, 16)\n",
    "ax1.set_ylabel('Mass flow')\n",
    "ax1.set_xlabel(\"Well head pressure\")\n",
    "ax1.set_title('$mf \\sim whp$')\n",
    "ax2.set_title('$mf \\sim whp + date$')\n",
    "ax3.set_title('$mf^2 \\sim whp^2 + date$')\n",
    "\n",
    "# create date colorbar\n",
    "indices = np.linspace(0, cmap.N, len(date_pred))\n",
    "my_colors = [cmap(int(i)) for i in indices]\n",
    "norm = Normalize(np.min(df['date']).year, np.max(df['date']).year)\n",
    "cb = ColorbarBase(ax4, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label('Year')\n",
    "\n",
    "linestyles = itertools.cycle(('-', '--', '-.', ':'))\n",
    "marker = itertools.cycle(['o', ',', '+', 'x', '*', '.'])\n",
    "\n",
    "# ===============================================================\n",
    "# Plot data\n",
    "# ===============================================================\n",
    "\n",
    "# plot raw data points\n",
    "for well in wells:\n",
    "    mkr = next(marker)\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.scatter('whp', 'mf', c='date_numeric', data=df.loc[df['well']==well], marker=mkr, label=well)\n",
    "    \n",
    "# plot fitted curves\n",
    "for well in wells:\n",
    "    lty = next(linestyles)\n",
    "    # model 1\n",
    "    # 'data' argument filters the data to just the data from one well\n",
    "    ax1.plot('whp', 'mf1', lty, data=pred[(pred['well']==well)])\n",
    "\n",
    "    # model 2 & 3\n",
    "    for i, date in enumerate(date_numeric_pred):\n",
    "        # 'data' argument similar, for a specific prediction date in the loop\n",
    "        ax2.plot('whp', 'mf2', lty, data=pred[(pred['well']==well) & (pred['date_numeric']==date)], c=my_colors[i])\n",
    "        ax3.plot('whp', 'mf3', lty, data=pred[(pred['well']==well) & (pred['date_numeric']==date)], c=my_colors[i])\n",
    "\n",
    "# show model selection criteria\n",
    "for ax, result in zip([ax1, ax2, ax3], [results1, results2, results3]):\n",
    "    ax.legend(['Adj $R^2$: %.2f' % result.rsquared_adj,\n",
    "               'AIC: %.2f' % result.aic], \n",
    "              handlelength=0, handletextpad=0, loc=1).legendHandles[0].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up PyJAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyjags\n",
    "import warnings\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "class MyModel(pyjags.Model):\n",
    "    \"\"\"\n",
    "    Create my own model child class that doesn't ValueError on unused variables\n",
    "    \"\"\"\n",
    "    def _init_compile(self, data, generate_data):\n",
    "        if data is None:\n",
    "            data = {}\n",
    "        data = pyjags.model.dict_to_jags(data)\n",
    "        unused = set(data.keys()) - set(self.variables)\n",
    "        if unused:\n",
    "#             warnings.warn('Unused data for variables: {}'.format(','.join(unused)))\n",
    "            pass\n",
    "        self.console.compile(data, self.chains, generate_data)\n",
    "        \n",
    "\n",
    "def make_prediction_data(whp_pred):\n",
    "    data_df = df.copy()\n",
    "    date_numeric_pred = [datetime_to_numeric(datetime.now())]\n",
    "    try: iter(whp_pred)\n",
    "    except TypeError: whp_pred = [whp_pred]\n",
    "    else: whp_pred = list(whp_pred)\n",
    "    mf_pred = [np.nan]\n",
    "    well_pred = df['well'].unique()\n",
    "    X = list(ParameterGrid({'date_numeric': date_numeric_pred,\n",
    "                            'whp': whp_pred,\n",
    "                            'mf': mf_pred,\n",
    "                            'well': well_pred}))\n",
    "    empty_rows = {key: [x[key] for x in X] for key in X[0].keys()}\n",
    "    \n",
    "    data_df = data_df.append(pd.DataFrame(empty_rows)).reset_index()\n",
    "    data = data_df.to_dict('list')\n",
    "    data['well_id'], unique_wells = data_df['well'].factorize()\n",
    "    data['well_id'] += 1\n",
    "    data['m'] = len(unique_wells)\n",
    "    data['n_init'] = len(df)\n",
    "    data['n'] = len(data_df)\n",
    "    for key in ['level_0', 'index', 'h', 'date', 'well']:\n",
    "        # rm unused variables\n",
    "        del data[key]\n",
    "    for key in data.keys():\n",
    "        # prepare np.nans for prediction\n",
    "        data[key] = np.ma.masked_invalid(data[key])\n",
    "    return data\n",
    "\n",
    "def run_model(data, n_chains=1, burn_in=100, n_samples=1000, variables=[]):\n",
    "    # variables: pass in a list of variables to track (if available in data)\n",
    "    model = MyModel(code, data=data, chains=n_chains, progress_bar=False)\n",
    "    model.sample(burn_in)\n",
    "    samples = model.sample(n_samples, vars=[x for x in variables if x in data.keys()])\n",
    "    samples = {key: values.squeeze() for key, values in samples.items()}\n",
    "    \n",
    "    # create sample frame with info from data\n",
    "    return_data = {key: [] for key in data.keys() if np.size(data[key]) == data['n']}\n",
    "    for key in return_data.keys():\n",
    "        return_data[key] = np.array(data[key][data['n_init']:data['n']])\n",
    "    return_data['mf'] = samples['mf'][data['n_init']:data['n']]\n",
    "    \n",
    "    # add back metadata\n",
    "    return_data['n'] = data['n'] - data['n_init']\n",
    "    return_data['m'] = data['m']\n",
    "    return_data['n_samples'] = n_samples\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "code = '''\n",
    "model {\n",
    "  # find means\n",
    "  mean_whp <- mean(whp)\n",
    "  mean_date_numeric <- mean(date_numeric)\n",
    "  \n",
    "  # transform to centered covariates\n",
    "  c_whp <- whp - mean_whp\n",
    "  c_date_numeric <- date_numeric - mean_date_numeric\n",
    "  \n",
    "  # fit individual regressions to wells\n",
    "  for (i in 1:n) {\n",
    "    #mu[i] <- Intercept[well_id[i]] + sqrt(max(mu2[i], 0)) + beta_date_numeric[well_id[i]] * c_date_numeric[i]\n",
    "    #mu2[i] <- beta_whp[well_id[i]] * pow(c_whp[i], 2) \n",
    "    mu[i] <- Intercept[well_id[i]] + beta_whp[well_id[i]] * c_whp[i] + beta_date_numeric[well_id[i]] * c_date_numeric[i]\n",
    "    mf[i] ~ dnorm(mu[i], tau)\n",
    "  }\n",
    "\n",
    "  I ~ dnorm(0, 1e-8)\n",
    "  b_w ~ dnorm(0, 1e-8)\n",
    "  b_d_n ~ dnorm(0, 1e-8)\n",
    "  \n",
    "  for (j in 1:m) {\n",
    "    Intercept[j] ~ dnorm(0, 1e-8)\n",
    "    beta_whp[j] ~ dnorm(0, 1e-8)\n",
    "    beta_date_numeric[j] ~ dnorm(0, 1e-6)\n",
    "  }\n",
    "\n",
    "  tau ~ dgamma(1e-6, 1e-6)\n",
    "\n",
    "  # make predictions\n",
    "  wk255_pred <- mu[n-1]\n",
    "  wk256_pred <- mu[n]\n",
    "}\n",
    "'''\n",
    "\n",
    "def plot_everything(whp=None):\n",
    "    fig, (ax, bar) = plt.subplots(1, 2, figsize=[14,4], gridspec_kw={'width_ratios': [19,1], 'wspace': 0.01})\n",
    "    ax.set_ylim([0, 1000])\n",
    "    ax.set_title('$mf \\sim whp + date$')\n",
    "    ax.set_ylabel('Mass flow')\n",
    "    ax.set_xlabel(\"Well head pressure\")\n",
    "    ax.set_xlim(0, 16)\n",
    "\n",
    "    # create date colorbar\n",
    "    indices = np.linspace(0, cmap.N, len(date_pred))\n",
    "    my_colors = [cmap(int(i)) for i in indices]\n",
    "    norm = Normalize(np.min(df['date']).year, np.max(df['date']).year)\n",
    "    cb = ColorbarBase(bar, cmap=cmap, norm=norm, orientation='vertical')\n",
    "    cb.set_label('Year')\n",
    "    linestyles = itertools.cycle(('-', '--', '-.', ':'))\n",
    "    marker = itertools.cycle(['o', ',', '+', 'x', '*', '.'])\n",
    "    \n",
    "    # plot raw data points\n",
    "    marker.__init__()\n",
    "    for well in wells:\n",
    "        mkr = next(marker)\n",
    "        ax.scatter('whp', 'mf', c='date_numeric', data=df.loc[df['well']==well], marker=mkr, label=well)\n",
    "\n",
    "    # plot linreg lines\n",
    "    linestyles = itertools.cycle(('-', '--', '-.', ':'))\n",
    "    for well in wells:\n",
    "        lty = next(linestyles)\n",
    "        for i, date in enumerate(date_numeric_pred):\n",
    "            plotdata = pred[(pred['well']==well) & (pred['date_numeric']==date)]\n",
    "            ax.plot('whp', 'mf2', lty, data=plotdata,\n",
    "                    c=my_colors[i], alpha=0.5)\n",
    "\n",
    "    # make and plot predictions of future measurements\n",
    "    data = make_prediction_data(whp)\n",
    "    samples = run_model(data, variables=['mf'])\n",
    "    for i in range(samples['n']):\n",
    "        ax.violinplot(samples['mf'][i], positions=[samples['whp'][i]], showmeans=True, showextrema=False)\n",
    "\n",
    "interact(plot_everything, whp=FloatSlider(min=0, max=16, value=12, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Flash Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    fpxl\n",
    "except: fpxl = pd.ExcelFile('../wairakei_data/Data for AU.xlsx')\n",
    "    \n",
    "fpdf = pd.read_excel(fpxl, 'calculation', header=1, usecols=\"D:E, J:L, N:P\")\n",
    "fpdf = fpdf.rename(columns={\"FP15\": \"well\", \"Unnamed: 1\": \"fp\",\n",
    "                            \"hf\": \"hf_ip\", \"hg\": \"hg_ip\", \"hfg\": \"hfg_ip\",\n",
    "                            \"hf.1\": \"hf_lp\", \"hg.1\": \"hg_lp\", \"hfg.1\": \"hfg_lp\"})\n",
    "# fpdf = fpdf[pd.to_numeric(fpdf['whp'], errors='coerce').notnull()]\n",
    "fpdf = fpdf[pd.to_numeric(fpdf['hf_ip'], errors='coerce').notnull()]  # make sure it has the necessary data\n",
    "for col in ['well', 'fp']:\n",
    "    fpdf[col] = fpdf[col].str.lower()\n",
    "fpdf[fpdf.columns] = fpdf[fpdf.columns].apply(pd.to_numeric, errors='ignore')\n",
    "fpdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find details of the last known operating conditions\n",
    "last_idx = df.groupby('well')['date_numeric'].idxmax()\n",
    "last_measurement = df.iloc[last_idx][['well', 'date_numeric', 'whp', 'h']]\n",
    "\n",
    "# set mapping of wells to FPs\n",
    "well_fp_map = pd.DataFrame({'well': ['wk255', 'wk258'],\n",
    "                            'fp':   ['fp15', 'fp16']})\n",
    "last_flows = last_measurement.merge(well_fp_map.merge(fpdf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_fp_data(flows, well_fp_map):\n",
    "    \"\"\"\n",
    "    Set up network prediction data from last known well whp & constants\n",
    "    \"\"\"\n",
    "    data_df = df.copy()\n",
    "    \n",
    "    # wells\n",
    "    flows['mf'] = np.nan\n",
    "    data_df = data_df.append(pd.DataFrame(flows)).reset_index()\n",
    "    data = data_df.to_dict('list')\n",
    "    data['well_id'], unique_wells = data_df['well'].factorize()\n",
    "    data['well_id'] += 1\n",
    "    data['m'] = len(unique_wells)\n",
    "    data['n_init'] = len(df)\n",
    "    data['n'] = len(data_df)\n",
    "    \n",
    "    # flash plants\n",
    "    fp_data = {}\n",
    "    fp_data['fp_id'], unique_fps = well_fp_map['fp'].factorize()\n",
    "    fp_data['fp_id'] += 1\n",
    "    fp_data['fp_sources'] = {key: [] for key in unique_fps + list(range())}\n",
    "    for well, fp in zip(well_fp_map['well'], well_fp_map['fp']):\n",
    "        fp_data['fp_sources'][fp].append(well)\n",
    "    for fp in fp_data['fp_sources'].keys():\n",
    "        fp_id = unique_fps.index(fp)\n",
    "        for well in fp_data['fp_sources'][fp]:\n",
    "            well_id = unique_wells.index(well)\n",
    "            \n",
    "            \n",
    "    print(fp_data)\n",
    "    for key in ['level_0', 'index', 'date', 'well']:\n",
    "        # rm unused variables\n",
    "        del data[key]\n",
    "    for key in data.keys():\n",
    "        # prepare np.nans for prediction\n",
    "        pass\n",
    "#         data[key] = np.ma.masked_invalid(data[key])\n",
    "    return data\n",
    "\n",
    "code_fp = '''\n",
    "model {\n",
    "  # find means\n",
    "  mean_whp <- mean(whp)\n",
    "  mean_date_numeric <- mean(date_numeric)\n",
    "  \n",
    "  # transform to centered covariates\n",
    "  c_whp <- whp - mean_whp\n",
    "  c_date_numeric <- date_numeric - mean_date_numeric\n",
    "  \n",
    "  # fit individual regressions to wells\n",
    "  for (i in 1:n) {\n",
    "    mu[i] <- Intercept[well_id[i]] + beta_whp[well_id[i]] * c_whp[i] + beta_date_numeric[well_id[i]] * c_date_numeric[i]\n",
    "    mf[i] ~ dnorm(mu[i], tau)\n",
    "  }\n",
    "  \n",
    "  for (j in 1:m) {\n",
    "    Intercept[j] ~ dnorm(0, 1e-6)\n",
    "    beta_whp[j] ~ dnorm(0, 1e-8)\n",
    "    beta_date_numeric[j] ~ dnorm(0, 1e-6)\n",
    "  }\n",
    "  tau ~ dgamma(1e-6, 1e-6)\n",
    "  \n",
    "  # estimate flow summaries to each FP\n",
    "  # requires n_init:n estimates to be in order of well id\n",
    "  for (j in (n_init+1):n) {\n",
    "    \n",
    "  }\n",
    "  \n",
    "  # estimate steam at FPs\n",
    "  for (k in 1:o) {\n",
    "    mf_fp[k] <- sum(mf[fp_sources[o]])\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = make_fp_data(last_flows, well_fp_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from iapws.iapws97 import IAPWS97\n",
    "\n",
    "sat_steam=IAPWS97(P=1,x=1)                #saturated steam with known P\n",
    "sat_liquid=IAPWS97(T=370, x=0)            #saturated liquid with known T\n",
    "steam=IAPWS97(P=2.5, T=500)               #steam with known P and T\n",
    "print(sat_steam.h, sat_liquid.h, steam.h) #calculated enthalpies\n",
    "IAPWS97(h=1101, P=0.626).h0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
