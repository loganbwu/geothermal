{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGSCI 700 Geothermal Reservoir Optimisation\n",
    "\n",
    "This workbook is for extracting Contact well data and recreating the plots.\n",
    "\n",
    "(Unix) launch with `cd src` >`jupyter notebook`\n",
    "\n",
    "File structure: \n",
    "```\n",
    "(root)\n",
    "├── src\n",
    "│    └── Python Test.ipynb\n",
    "└── wairakei_data\n",
    "     └── Liquid wells (version 1).xlsx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import scipy.stats as stats\n",
    "from datetime import datetime, timedelta\n",
    "from plotnine import *\n",
    "%matplotlib inline\n",
    "\n",
    "base_year = '2000'    # numeric dates calculated from Jan-01\n",
    "\n",
    "def datetime_to_numeric(my_datetime):\n",
    "    # returns days since base_year-01-01.\n",
    "    try:\n",
    "        date_numeric = (my_datetime - datetime(int(base_year),1,1)) / timedelta(days=1)   # datetime implem\n",
    "    except:\n",
    "        date_numeric = (my_datetime - np.datetime64(base_year)) / np.timedelta64(1, 'D')  # numpy implem\n",
    "    return date_numeric\n",
    "\n",
    "# Check if Excel file is already in memory (loading is slow)\n",
    "try:    xl\n",
    "except: xl = pd.ExcelFile('../wairakei_data/Liquid wells (version 1).xlsx')\n",
    "print(\"Sheets:\", ', '.join([x for x in xl.sheet_names if set(x) & set('FtT(L') == set()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets to load data from\n",
    "sheets = ['wk255', 'wk256', 'w258', 'w259']\n",
    "# sheets = ['wk247', 'w253', 'w254', 'w258', 'w259', 'w267', 'w268', 'wk255', 'wk256', 'w269', 'WK270', 'WK271', 'WK272']\n",
    "# wells = ['wk255', 'wk256', 'wk247', 'w267', 'w268',\n",
    "#          'w269', 'WK270', 'WK271', 'WK272']\n",
    "        # missing: wk251, wk250, wk252, wk238, wk234, wk240, wk241, wk267, wk268\n",
    "\n",
    "dfs = []\n",
    "for sheet in sheets:\n",
    "    df = xl.parse(sheet)                                       # select well data\n",
    "    df['well'] = sheet                                            # label data with well name\n",
    "    dfs.append(df)\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "# df = df.loc[:, ~df.columns.str.contains('^Unnamed|SUMMARY|slope|intercept')]     # remove extra columns\n",
    "df = df[['date', 'whp', 'mf', 'h', 'well']]                      # instead, only keep certain columns\n",
    "df['well'] = df['well'].str.lower()                              # remove 'WK' inconsistencies\n",
    "df['well'] = df['well'].str.replace(\"^[^\\d]*\", \"wk\")\n",
    "df['mf'] = pd.to_numeric(df['mf'], errors='coerce')              # remove 'dummy' entries\n",
    "df = df.dropna(subset=['date', 'whp', 'mf'])                     # remove NA\n",
    "\n",
    "df['date_numeric'] = datetime_to_numeric(df['date']) #  yrs since base_year\n",
    "df = df.reset_index(drop=True)\n",
    "wells = df['well'].unique()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up regression data and create prediction frame for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_pred = np.arange(df['date'].min(), df['date'].max(), np.timedelta64(365*2, 'D').astype(datetime))\n",
    "date_numeric_pred = datetime_to_numeric(date_pred)\n",
    "whp_pred = np.linspace(0, 16, 1000)\n",
    "well_pred = wells\n",
    "pred = pd.DataFrame(list(itertools.product(date_numeric_pred, whp_pred, well_pred)),\n",
    "                    columns=['date_numeric', 'whp', 'well'])\n",
    "pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform regression and prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Not conditioned on date\n",
    "model1 = ols(\"mf ~ well * whp\", data=df)\n",
    "results1 = model1.fit()\n",
    "pred['mf1'] = results1.predict(pred)\n",
    "\n",
    "# Linear fit dependent on date\n",
    "model2 = ols(\"mf ~ well * (whp + date_numeric)\", data=df)\n",
    "results2 = model2.fit()\n",
    "pred['mf2'] = results2.predict(pred)\n",
    "\n",
    "# Elliptic fit dependent on date\n",
    "model3 = ols(\"np.power(mf,2) ~ well * (np.power(whp,2) + date_numeric)\", data=df)\n",
    "results3 = model3.fit()\n",
    "pred['mf3^2'] = results3.predict(pred)\n",
    "pred.loc[pred['mf3^2'] < 0, 'mf3^2'] = np.nan    # remove invalid results\n",
    "pred['mf3'] = np.sqrt(pred['mf3^2'])\n",
    "\n",
    "pred.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.colorbar import ColorbarBase\n",
    "\n",
    "# ===============================================================\n",
    "# Set up axes\n",
    "# ===============================================================\n",
    "\n",
    "# colors\n",
    "cmap = plt.get_cmap('viridis')\n",
    "indices = np.linspace(0, cmap.N, len(df))\n",
    "my_colors = [cmap(int(i)) for i in indices]\n",
    "\n",
    "# subplots\n",
    "fig, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=[14,4], gridspec_kw={'width_ratios': [9,9,9,1]})\n",
    "ax1.get_shared_y_axes().join(ax1, ax2, ax3)\n",
    "ax1.set_ylim([0, 1000])\n",
    "ax1.set_xlim(0, 16)\n",
    "ax1.set_ylabel('Mass flow')\n",
    "ax1.set_xlabel(\"Well head pressure\")\n",
    "ax1.set_title('$mf \\sim whp$')\n",
    "ax2.set_title('$mf \\sim whp + date$')\n",
    "ax3.set_title('$mf^2 \\sim whp^2 + date$')\n",
    "\n",
    "# create date colorbar\n",
    "indices = np.linspace(0, cmap.N, len(date_pred))\n",
    "my_colors = [cmap(int(i)) for i in indices]\n",
    "norm = Normalize(np.min(df['date']).year, np.max(df['date']).year)\n",
    "cb = ColorbarBase(ax4, cmap=cmap, norm=norm, orientation='vertical')\n",
    "cb.set_label('Year')\n",
    "\n",
    "linestyles = itertools.cycle(('-', '--', '-.', ':'))\n",
    "marker = itertools.cycle(['o', ',', '+', 'x', '*', '.'])\n",
    "\n",
    "# ===============================================================\n",
    "# Plot data\n",
    "# ===============================================================\n",
    "\n",
    "# plot raw data points\n",
    "for well in wells:\n",
    "    mkr = next(marker)\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.scatter('whp', 'mf', c='date_numeric', data=df.loc[df['well']==well], marker=mkr, label=well)\n",
    "    \n",
    "# plot fitted curves\n",
    "for well in wells:\n",
    "    lty = next(linestyles)\n",
    "    # model 1\n",
    "    # 'data' argument filters the data to just the data from one well\n",
    "    ax1.plot('whp', 'mf1', lty, data=pred[(pred['well']==well)])\n",
    "\n",
    "    # model 2 & 3\n",
    "    for i, date in enumerate(date_numeric_pred):\n",
    "        # 'data' argument similar, for a specific prediction date in the loop\n",
    "        ax2.plot('whp', 'mf2', lty, data=pred[(pred['well']==well) & (pred['date_numeric']==date)], c=my_colors[i])\n",
    "        ax3.plot('whp', 'mf3', lty, data=pred[(pred['well']==well) & (pred['date_numeric']==date)], c=my_colors[i])\n",
    "\n",
    "# show model selection criteria\n",
    "for ax, result in zip([ax1, ax2, ax3], [results1, results2, results3]):\n",
    "    ax.legend(['Adj $R^2$: %.2f' % result.rsquared_adj,\n",
    "               'AIC: %.2f' % result.aic], \n",
    "              handlelength=0, handletextpad=0, loc=1).legendHandles[0].set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up PyJAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyjags\n",
    "import warnings\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "class MyModel(pyjags.Model):\n",
    "    \"\"\"\n",
    "    Create my own model child class that doesn't ValueError on unused variables\n",
    "    \"\"\"\n",
    "    def _init_compile(self, data, generate_data):\n",
    "        if data is None:\n",
    "            data = {}\n",
    "        data = pyjags.model.dict_to_jags(data)\n",
    "        unused = set(data.keys()) - set(self.variables)\n",
    "        if unused:\n",
    "#             warnings.warn('Unused data for variables: {}'.format(','.join(unused)))\n",
    "            pass\n",
    "        self.console.compile(data, self.chains, generate_data)\n",
    "        \n",
    "\n",
    "def make_prediction_data(whp_pred):\n",
    "    data_df = df.copy()\n",
    "    date_numeric_pred = [datetime_to_numeric(datetime.now())]\n",
    "    try: iter(whp_pred)\n",
    "    except TypeError: whp_pred = [whp_pred]\n",
    "    else: whp_pred = list(whp_pred)\n",
    "    mf_pred = [np.nan]\n",
    "    well_pred = df['well'].unique()\n",
    "    X = list(ParameterGrid({'date_numeric': date_numeric_pred,\n",
    "                            'whp': whp_pred,\n",
    "                            'mf': mf_pred,\n",
    "                            'well': well_pred}))\n",
    "    empty_rows = {key: [x[key] for x in X] for key in X[0].keys()}\n",
    "    \n",
    "    data_df = data_df.append(pd.DataFrame(empty_rows)).reset_index()\n",
    "    data = data_df.to_dict('list')\n",
    "    data['well_id'], unique_wells = data_df['well'].factorize()\n",
    "    data['well_id'] += 1\n",
    "    data['m'] = len(unique_wells)\n",
    "    data['n_init'] = len(df)\n",
    "    data['n'] = len(data_df)\n",
    "    for key in ['index', 'h', 'date', 'well']:\n",
    "        # rm unused variables\n",
    "        del data[key]\n",
    "    # prepare np.nans for prediction\n",
    "#     data = {key: np.ma.masked_invalid(values) for key, values in data.items()}\n",
    "    data['mf'] = np.ma.masked_invalid(data['mf'])\n",
    "    return data\n",
    "\n",
    "def run_model(data, n_chains=1, burn_in=100, n_samples=1000, variables=[]):\n",
    "    # variables: pass in a list of variables to track (if available in data)\n",
    "    model = MyModel(code, data=data, chains=n_chains, progress_bar=False)\n",
    "    model.sample(burn_in)\n",
    "    samples = model.sample(n_samples, vars=[x for x in variables if x in data.keys()])\n",
    "    samples = {key: values.squeeze() for key, values in samples.items()}\n",
    "    \n",
    "    # create sample frame with info from data\n",
    "    return_data = {key: [] for key in data.keys() if np.size(data[key]) == data['n']}\n",
    "    for key in return_data.keys():\n",
    "        return_data[key] = np.array(data[key][data['n_init']:data['n']])\n",
    "    return_data['mf'] = samples['mf'][data['n_init']:data['n']]\n",
    "    \n",
    "    # add back metadata\n",
    "    return_data['n'] = data['n'] - data['n_init']\n",
    "    return_data['m'] = data['m']\n",
    "    return_data['n_samples'] = n_samples\n",
    "    \n",
    "    return return_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, FloatSlider\n",
    "\n",
    "code = '''\n",
    "data {\n",
    "  # find means\n",
    "  mean_whp <- mean(whp)\n",
    "  mean_date_numeric <- mean(date_numeric)\n",
    "  \n",
    "  # transform to centered covariates\n",
    "  c_whp <- whp - mean_whp\n",
    "  c_date_numeric <- date_numeric - mean_date_numeric\n",
    "}\n",
    "model {\n",
    "  # fit individual regressions to wells\n",
    "  for (i in 1:n) {\n",
    "    #mu[i] <- Intercept[well_id[i]] + sqrt(max(mu2[i], 0)) + beta_date_numeric[well_id[i]] * c_date_numeric[i]\n",
    "    #mu2[i] <- beta_whp[well_id[i]] * pow(c_whp[i], 2) \n",
    "    mu[i] <- Intercept[well_id[i]] + beta_whp[well_id[i]] * c_whp[i] + beta_date_numeric[well_id[i]] * c_date_numeric[i]\n",
    "    mf[i] ~ dnorm(mu[i], tau)\n",
    "  }\n",
    "\n",
    "  I ~ dnorm(0, 1e-8)\n",
    "  b_w ~ dnorm(0, 1e-8)\n",
    "  b_d_n ~ dnorm(0, 1e-8)\n",
    "  \n",
    "  for (j in 1:m) {\n",
    "    Intercept[j] ~ dnorm(0, 1e-8)\n",
    "    beta_whp[j] ~ dnorm(0, 1e-8)\n",
    "    beta_date_numeric[j] ~ dnorm(0, 1e-6)\n",
    "  }\n",
    "\n",
    "  tau ~ dgamma(1e-6, 1e-6)\n",
    "\n",
    "  # make predictions\n",
    "  wk255_pred <- mu[n-1]\n",
    "  wk256_pred <- mu[n]\n",
    "}\n",
    "'''\n",
    "\n",
    "def plot_everything(whp=None):\n",
    "    fig, (ax, bar) = plt.subplots(1, 2, figsize=[12,4], gridspec_kw={'width_ratios': [19,1], 'wspace': 0.01})\n",
    "    ax.set_ylim([0, 1000])\n",
    "    ax.set_title('$mf^2 \\sim whp^2 + date$')\n",
    "    ax.set_ylabel('Mass flow')\n",
    "    ax.set_xlabel(\"Well head pressure\")\n",
    "    ax.set_xlim(0, 16)\n",
    "\n",
    "    # create date colorbar\n",
    "    indices = np.linspace(0, cmap.N, len(date_pred))\n",
    "    my_colors = [cmap(int(i)) for i in indices]\n",
    "    norm = Normalize(np.min(df['date']).year, np.max(df['date']).year)\n",
    "    cb = ColorbarBase(bar, cmap=cmap, norm=norm, orientation='vertical')\n",
    "    cb.set_label('Year')\n",
    "    linestyles = itertools.cycle(('-', '--', '-.', ':'))\n",
    "    marker = itertools.cycle(['o', ',', '+', 'x', '*', '.'])\n",
    "    \n",
    "    # plot raw data points\n",
    "    marker.__init__()\n",
    "    for well in wells:\n",
    "        mkr = next(marker)\n",
    "        ax.scatter('whp', 'mf', c='date_numeric', data=df.loc[df['well']==well], marker=mkr, label=well)\n",
    "\n",
    "    # plot linreg lines\n",
    "    linestyles = itertools.cycle(('-', '--', '-.', ':'))\n",
    "    for well in wells:\n",
    "        lty = next(linestyles)\n",
    "        for i, date in enumerate(date_numeric_pred):\n",
    "            plotdata = pred[(pred['well']==well) & (pred['date_numeric']==date)]\n",
    "            ax.plot('whp', 'mf3', lty, data=plotdata,\n",
    "                    c=my_colors[i], alpha=0.5)\n",
    "\n",
    "    # make and plot predictions of future measurements\n",
    "    data = make_prediction_data(whp)\n",
    "    samples = run_model(data, variables=['mf'])\n",
    "    for i in range(samples['n']):\n",
    "        ax.violinplot(samples['mf'][i], positions=[samples['whp'][i]], showmeans=True, showextrema=False)\n",
    "#     fig.savefig('this.png', dpi=300, bbox_inches='tight')\n",
    "\n",
    "# interact(plot_everything, whp=FloatSlider(min=0, max=16, value=12, continuous_update=False));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Flash Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and process data\n",
    "try:    fpxl\n",
    "except: fpxl = pd.ExcelFile('../wairakei_data/Data for AU.xlsx')\n",
    "    \n",
    "fpdf = pd.read_excel(fpxl, 'calculation', header=1, usecols=\"D:E, J:L, N:P\")\n",
    "fpdf = fpdf.rename(columns={\"FP15\": \"well\", \"Unnamed: 1\": \"fp\",\n",
    "                            \"hf\": \"hf_ip\", \"hg\": \"hg_ip\", \"hfg\": \"hfg_ip\",\n",
    "                            \"hf.1\": \"hf_lp\", \"hg.1\": \"hg_lp\", \"hfg.1\": \"hfg_lp\"})\n",
    "fpdf = fpdf[pd.to_numeric(fpdf['hf_ip'], errors='coerce').notnull()]  # make sure it has the necessary data\n",
    "for col in ['well', 'fp']:\n",
    "    fpdf[col] = fpdf[col].str.lower()\n",
    "fpdf[fpdf.columns] = fpdf[fpdf.columns].apply(pd.to_numeric, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find details of the last known operating conditions\n",
    "last_idx = df.groupby('well')['date_numeric'].idxmax()\n",
    "last_measurement = df.iloc[last_idx][['well', 'date_numeric', 'whp', 'h']]\n",
    "\n",
    "# set mapping of wells to FPs\n",
    "well_fp_map = pd.DataFrame({'well': ['wk247', 'wk253', 'wk254', 'wk255', 'wk256', 'wk258', 'wk259', 'wk267', 'wk268', 'wk269', 'wk270', 'wk271', 'wk272'],\n",
    "                            'fp':   ['fp15', 'fp16',  'fp16',  'fp15',  'fp15',  'fp16',  'fp16',  'fp16',  'fp16',  'fp15',  'fp15',  'fp15',  'fp15']})\n",
    "# remove absent wells from map\n",
    "well_fp_map = well_fp_map[well_fp_map['well'].isin(wells)]\n",
    "\n",
    "last_flows = last_measurement.merge(well_fp_map.merge(fpdf))\n",
    "well_fp_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_fp = '''\n",
    "data {\n",
    "  # find means\n",
    "  mean_whp <- mean(whp)\n",
    "  mean_date_numeric <- mean(date_numeric)\n",
    "  \n",
    "  # transform to centered covariates\n",
    "  c_whp <- whp - mean_whp\n",
    "  c_date_numeric <- date_numeric - mean_date_numeric\n",
    "  \n",
    "  c_whp_pred <- whp_pred - mean_whp\n",
    "  c_date_numeric_pred <- date_numeric_pred - mean_date_numeric\n",
    "}\n",
    "model {\n",
    "  # fit individual regressions to wells\n",
    "  for (i in 1:n_data) {\n",
    "    mu[i] <- Intercept[well_id[i]] + beta_whp[well_id[i]] * c_whp[i] + beta_date_numeric[well_id[i]] * c_date_numeric[i]\n",
    "    mf[i] ~ dnorm(mu[i], tau)\n",
    "  }\n",
    "  \n",
    "  for (j in 1:n_wells) {\n",
    "    Intercept[j] ~ dnorm(0, 1e-6)\n",
    "    beta_whp[j] ~ dnorm(0, 1e-8)\n",
    "    beta_date_numeric[j] ~ dnorm(0, 1e-6)\n",
    "  }\n",
    "  tau ~ dgamma(1e-6, 1e-6)\n",
    "  \n",
    "  for (i in 1:n_wells) {\n",
    "    mu_pred[i] <- Intercept[i] + beta_whp[i] * c_whp_pred[i] + beta_date_numeric[i] * c_date_numeric_pred\n",
    "    #mf_pred[i] ~ dnorm(mu_pred[i], tau)\n",
    "    mf_pred[i] <- mu_pred[i]\n",
    "  }\n",
    "  \n",
    "  # estimate steam at FPs using weighted sums\n",
    "  for (k in 1:n_fps) {\n",
    "    mf_fp[k] <- sum(mf_pred[map[k, 1:n_fp_inflows[k]]])\n",
    "    h_fp[k] <- sum(mf_pred[map[k, 1:n_fp_inflows[k]]] * h[map[k, 1:n_fp_inflows[k]]]) / max(mf_fp[k], 1e-4)\n",
    "    #h_fp[k] <- sum(mf_pred[map[k, 1:n_fp_inflows[k]]] * h[map[k, 1:n_fp_inflows[k]]]) / mf_fp[k]\n",
    "  }\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(df=None, flows=None, well_fp_map=None, date_numeric_pred=datetime_to_numeric(datetime.now())):\n",
    "    # deal with well data\n",
    "    data_df = df.copy()\n",
    "    data_df['well_id'], unique_wells = data_df['well'].factorize()\n",
    "    data_df['well_id'] += 1\n",
    "    unique_wells_dict = {k: v+1 for v, k in enumerate(unique_wells)}\n",
    "#     print(data_df)\n",
    "    \n",
    "    # set up data for flash plant\n",
    "    flows_df = flows.copy().rename(columns={'mf': 'mf_fp', 'whp': 'whp_pred'}).drop('date_numeric',1)\n",
    "    flows_df['fp_id'], unique_fps = flows_df['fp'].factorize()\n",
    "    flows_df['fp_id'] += 1\n",
    "    unique_fps_dict = {k: v+1 for v, k in enumerate(unique_fps)}\n",
    "    flows_df = flows_df.drop(['well', 'fp'], 1)\n",
    "#     print(flows_df)\n",
    "    \n",
    "    # each fp draws from which wells: {fp: [wells]}\n",
    "    map_df = well_fp_map.copy()\n",
    "    map_df['fp_id'] = map_df['fp'].replace(unique_fps_dict)\n",
    "    map_df['well_id'] = map_df['well'].replace(unique_wells_dict)\n",
    "    map_df = map_df.groupby('fp_id')['well_id'].apply(list).to_frame()\n",
    "    map_dict = {}\n",
    "    inflows = map_df['well_id'].tolist()\n",
    "    map_dict['n_fp_inflows'] = [len(x) for x in inflows]\n",
    "    map_dict['map'] = np.zeros(shape=(len(inflows), max(map_dict['n_fp_inflows'])), dtype=int)\n",
    "    for i, inflows in enumerate(inflows):\n",
    "        map_dict['map'][i,0:map_dict['n_fp_inflows'][i]] = inflows\n",
    "#     print(\"Map\", map_dict)\n",
    "    \n",
    "    # set up stochastic nodes for fps\n",
    "    fp_dict = flows_df.to_dict('list')\n",
    "    fp_dict['n_fps'] = len(unique_fps)\n",
    "    fp_dict['mf_pred'] = np.ma.masked_invalid([np.nan]*len(unique_wells))\n",
    "    fp_dict['date_numeric_pred'] = date_numeric_pred\n",
    "#     print(\"FP\", flows_df)\n",
    "    \n",
    "    data = data_df.to_dict('list')\n",
    "    data['n_wells'] = len(unique_wells)\n",
    "    data['n_data'] = len(data_df)\n",
    "    data['mf_pred'] = np.ma.masked_invalid([np.nan])\n",
    "    metadata = {}\n",
    "    metadata['unique_wells'] = list(unique_wells)\n",
    "    metadata['unique_fps'] = list(unique_fps)\n",
    "    \n",
    "    data.update(map_dict)\n",
    "    data.update(fp_dict)\n",
    "    \n",
    "    for key in ['date', 'well']:\n",
    "        del data[key]\n",
    "    return data, metadata\n",
    "    \n",
    "make_data(df, last_flows, well_fp_map)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chains = 1\n",
    "burn_in = 500\n",
    "\n",
    "data_fp, metadata = make_data(df, last_flows, well_fp_map)\n",
    "model_fp = MyModel(code_fp, data=data_fp, chains=n_chains, progress_bar=False)\n",
    "model_fp.sample(burn_in)\n",
    "samples_fp = model_fp.sample(10000, vars=['mf_pred', 'mf_fp', 'h_fp'])\n",
    "\n",
    "outframe_fp = pd.DataFrame(samples_fp['mf_fp'].squeeze().T)\n",
    "outframe_fp.columns = metadata['unique_fps']\n",
    "outframe_fp = outframe_fp.melt(var_name='name')\n",
    "outframe_fp['facility'] = 'Flash plants'\n",
    "\n",
    "outframe_h_fp = pd.DataFrame(samples_fp['h_fp'].squeeze().T)\n",
    "outframe_h_fp.columns = metadata['unique_fps']\n",
    "outframe_h_fp = outframe_h_fp.melt(var_name='name')\n",
    "outframe_h_fp['facility'] = 'FP (enthalpy)'\n",
    "\n",
    "outframe_well = pd.DataFrame(samples_fp['mf_pred'].squeeze().T)\n",
    "outframe_well.columns = metadata['unique_wells']\n",
    "outframe_well = outframe_well.melt(var_name='name')\n",
    "outframe_well['facility'] = 'Wells'\n",
    "\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=[14,4])\n",
    "for name in metadata['unique_wells']:\n",
    "    sns.distplot(outframe_well['value'].loc[outframe_well['name']==name], ax=ax1)\n",
    "ax1.set_xlabel(\"Mass flow\")\n",
    "ax1.legend(metadata['unique_wells'])\n",
    "for name in metadata['unique_fps']:\n",
    "    sns.distplot(outframe_fp['value'].loc[outframe_fp['name']==name], fit=stats.norm, ax=ax2)\n",
    "ax2.set_xlabel(\"Mass flow\")\n",
    "ax2.legend(metadata['unique_fps'])\n",
    "for name in metadata['unique_fps']:\n",
    "    sns.distplot(outframe_h_fp['value'].loc[outframe_fp['name']==name], fit=stats.norm, ax=ax3)\n",
    "ax3.set_xlabel(\"Enthalpy\")\n",
    "ax3.legend(metadata['unique_fps'])\n",
    "\n",
    "outframe_all = outframe_fp.append(outframe_well).append(outframe_h_fp)\n",
    "# ggplot(outframe_all, aes(x='value', fill='name')) + geom_density(alpha=0.25) + facet_wrap('~facility', scales='free')\n",
    "# ggplot(outframe_fp, aes(x='mf', fill='fp')) + geom_density(alpha=0.25)\n",
    "ggplot(outframe_well, aes(x='value')) + geom_density(alpha=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '''\n",
    "model {\n",
    "    z <- x - 10\n",
    "    a <- sum(x*x)\n",
    "    for (i in 1:2) {\n",
    "        b[i] <- sum(x[y[i,1:n_col[i]]])\n",
    "    }\n",
    "}\n",
    "'''\n",
    "\n",
    "data = {'x': [10,20,40], 'y': np.array([[1,2], [1,3]]), 'n_col': [2,2]}\n",
    "model = MyModel(code, data, chains=1)\n",
    "model.sample(1, vars=['a'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
