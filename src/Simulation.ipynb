{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ENGSCI 700 Geothermal Reservoir Optimisation\n",
    "\n",
    "This workbook is for extracting Contact well data and recreating the plots.\n",
    "\n",
    "(Unix) launch with `cd src` >`jupyter notebook`\n",
    "\n",
    "File structure: \n",
    "```\n",
    "(root)\n",
    "├── src\n",
    "│    └── Python Test.ipynb\n",
    "└── wairakei_data\n",
    "     └── Liquid wells (version 1).xlsx\n",
    "     └── short version Generation Projection 2016.xlsx\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime, timedelta\n",
    "from IPython.display import display, HTML\n",
    "import os\n",
    "import pyjags\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "pyjags.load_module('glm')\n",
    "\n",
    "base_year = '2000'    # numeric dates calculated from Jan-01\n",
    "configpath = '../wairakei_data/config.xlsx'\n",
    "\n",
    "def read_binary_solution(path='../wairakei_data/toy-network-v4.xlsm'):\n",
    "    # read from Vida's toy model workbook\n",
    "    xlfile = pd.ExcelFile(path)\n",
    "    sheet = xlfile.parse('Full LP')\n",
    "    sheet = sheet.loc[sheet.count(1)>50]  # arbitrary, anything works\n",
    "    sheet = sheet.transpose()\n",
    "    sheet.columns = ['used', 'combination']\n",
    "    combinations = pd.DataFrame([x.split('-') for x in sheet.query('used==1')['combination']],\n",
    "                               columns = ['well', 'fp'])\n",
    "    combinations['well'] = 'wk' + combinations['well']\n",
    "    combinations['fp'] = 'fp' + combinations['fp']\n",
    "    return(combinations)\n",
    "\n",
    "class MyModel(pyjags.Model):\n",
    "    \"\"\"\n",
    "    Create my own model child class that doesn't ValueError on unused variables\n",
    "    \"\"\"\n",
    "    def _init_compile(self, data, generate_data):\n",
    "        if data is None:\n",
    "            data = {}\n",
    "        data = pyjags.model.dict_to_jags(data)\n",
    "        unused = set(data.keys()) - set(self.variables)\n",
    "        if unused:\n",
    "#             warnings.warn('Unused data for variables: {}'.format(','.join(unused)))\n",
    "            pass\n",
    "        self.console.compile(data, self.chains, generate_data)\n",
    "\n",
    "def dt2num(my_datetime):\n",
    "    # returns days since base_year-01-01.\n",
    "    try:\n",
    "        date_numeric = (my_datetime - datetime(int(base_year),1,1)) / timedelta(days=1)   # datetime implem\n",
    "    except:\n",
    "        date_numeric = (my_datetime - np.datetime64(base_year)) / np.timedelta64(1, 'D')  # numpy implem\n",
    "    return date_numeric\n",
    "\n",
    "def myprint(df):\n",
    "    display(HTML(df.to_html()))\n",
    "    \n",
    "def central(data, m=3.29):\n",
    "    return data[abs(data - np.mean(data)) < m * np.std(data)]\n",
    "\n",
    "# Check if Excel file is already in memory (loading is slow)\n",
    "try:    xl\n",
    "except: xl = pd.ExcelFile('../wairakei_data/Liquid wells (version 1).xlsx')\n",
    "sheetlist = [x for x in xl.sheet_names if set(x) & set('FtT(L') == set()]\n",
    "print(\"Sheets:\", ', '.join(sheetlist))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sheets to load data from\n",
    "sheets = ['WK27 curve', 'wk247', 'w253', 'w254', 'w258', 'w259', 'w267', 'w268', 'wk255', 'wk256', 'w269', 'WK270', 'WK271', 'WK272']\n",
    "sheets = sheetlist\n",
    "\n",
    "dfs = []\n",
    "for sheet in sheets:\n",
    "    try:\n",
    "        df = xl.parse(sheet)                                       # select well data\n",
    "        df['well'] = sheet                                            # label data with well name\n",
    "        dfs.append(df)\n",
    "    except:\n",
    "        print(f'Failed on sheet {sheet}')\n",
    "df = pd.concat(dfs)\n",
    "\n",
    "df = df[['date', 'whp', 'mf', 'h', 'well']]                      # only keep certain columns\n",
    "df['well'] = df['well'].str.lower()                              # remove 'WK' inconsistencies\n",
    "df['well'] = df['well'].str.replace(\"^[^\\d]*\", \"wk\")\n",
    "df['well'] = df['well'].str.strip()\n",
    "df['mf'] = pd.to_numeric(df['mf'], errors='coerce')              # remove 'dummy' entries\n",
    "df = df.dropna(subset=['date', 'whp', 'mf'])                     # remove NA\n",
    "\n",
    "df['date_numeric'] = dt2num(df['date']) #  yrs since base_year\n",
    "regression_df = df.reset_index(drop=True)\n",
    "wells = regression_df['well'].unique()\n",
    "print(wells)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduce Flash Plants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import and process data\n",
    "try:    fpxl\n",
    "except: fpxl = pd.ExcelFile('../wairakei_data/Data for AU.xlsx')\n",
    "    \n",
    "fpdf = pd.read_excel(fpxl, 'calculation', header=1, usecols=\"D:E, J:L, N:P\")\n",
    "fpdf = fpdf.rename(columns={\"FP15\": \"well\", \"Unnamed: 1\": \"fp\",\n",
    "                            \"hf\": \"hf_ip\", \"hg\": \"hg_ip\", \"hfg\": \"hfg_ip\",\n",
    "                            \"hf.1\": \"hf_lp\", \"hg.1\": \"hg_lp\", \"hfg.1\": \"hfg_lp\"})\n",
    "fpdf = fpdf[pd.to_numeric(fpdf['hf_ip'], errors='coerce').notnull()]  # make sure it has the necessary data\n",
    "for col in ['well', 'fp']:\n",
    "    fpdf[col] = fpdf[col].str.lower()\n",
    "fpdf[fpdf.columns] = fpdf[fpdf.columns].apply(pd.to_numeric, errors='ignore')\n",
    "fpdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_config(configpath):\n",
    "    # only use if it gets lost. Will refresh file\n",
    "    well_fp_map = pd.DataFrame({'well': ['wk27', 'wk242', 'wk247', 'wk253', 'wk254', 'wk255', 'wk256', 'wk258', 'wk259', 'wk267', 'wk268', 'wk269', 'wk270', 'wk271', 'wk272'],\n",
    "                                'fp':   ['fp1',  'fp14',  'fp15', 'fp16',  'fp16',  'fp15',  'fp15',  'fp16',  'fp16',  'fp16',  'fp16',  'fp15',  'fp15',  'fp14',  'fp14']},\n",
    "                               columns=['well', 'fp'])\n",
    "    fp_gen_map = pd.DataFrame({'fp':     ['abandoned', 'poi dry', 'direct ip', 'fp1', 'fp14', 'fp15', 'fp16', 'fp2', 'fp4', 'fp5', 'fp9-10'],\n",
    "                               'gen_ip': [ None,       'POI',      None,       'WRK', 'WRK',  'THI',  'POI',  'WRK', 'WRK', 'WRK', 'WRK'   ],\n",
    "                               'gen_lp': [ None,       'POI',      None,       'WRK', 'WRK',  'THI',  'POI',  'WRK', 'WRK', 'WRK', 'WRK'   ],\n",
    "                               'gen_w':  [ None,        None,      None,       'BIN',  None,   None,   None,  'BIN', 'BIN', 'BIN', 'BIN'   ]},\n",
    "                              columns=['fp', 'gen_ip', 'gen_lp', 'gen_w'])\n",
    "    gen_constants = pd.DataFrame({'gen':    ['WRK', 'THI', 'BIN', 'POI' ],\n",
    "                                  'ip':     [ True,  True,  False, True ],\n",
    "                                  'lp':     [ True,  True,  False, True ],\n",
    "                                  'bin':    [ False, False, True,  False],\n",
    "                                  'factor': [ 9.2,   8.22,  178.9, 7.76]},  # m3/MW\n",
    "                                 columns=['gen', 'ip', 'lp', 'bin', 'factor'])\n",
    "    # find details of the last known operating conditions\n",
    "    last_idx = regression_df.groupby('well')['date_numeric'].idxmax()\n",
    "    operating_conditions = regression_df.iloc[last_idx][['well', 'whp', 'h']]\n",
    "\n",
    "    # set constants (could use median)\n",
    "    fp_constants = fpdf.groupby('fp').mean().reset_index()\n",
    "\n",
    "    if os.path.exists(configpath):\n",
    "        os.remove(configpath)\n",
    "    config_writer = pd.ExcelWriter('../wairakei_data/config.xlsx')\n",
    "    print(\"Writing config data to\", configpath)\n",
    "    configdata = {'well_fp_map': well_fp_map,\n",
    "                  'fp_gen_map': fp_gen_map,\n",
    "                  'operating_conditions': operating_conditions,\n",
    "                  'fp_constants': fp_constants,\n",
    "                  'gen_constants': gen_constants}\n",
    "    for sheetname, df in configdata.items():\n",
    "        df.to_excel(config_writer, sheetname, index=False)\n",
    "    config_writer.save()\n",
    "    return pd.ExcelFile(configpath)\n",
    "\n",
    "\n",
    "try:\n",
    "    config = pd.ExcelFile(configpath)\n",
    "except FileNotFoundError:\n",
    "    print(\"Warning: are you sure you want to overwrite the config file?\")\n",
    "    config = write_config(configpath)\n",
    "\n",
    "configdata = pd.read_excel(config, None)\n",
    "locals().update(configdata)\n",
    "\n",
    "well_fp_map = read_binary_solution()\n",
    "# remove absent wells and fps from data before proceeding\n",
    "well_fp_map = well_fp_map[well_fp_map['well'].isin(wells)].sort_values('well')\n",
    "operating_conditions = operating_conditions[operating_conditions['well'].isin(wells)].sort_values('well')\n",
    "fp_constants = fp_constants[fp_constants['fp'].isin(well_fp_map['fp'])].sort_values('fp')\n",
    "fp_gen_map = fp_gen_map[fp_gen_map['fp'].isin(well_fp_map['fp'])].sort_values('fp')\n",
    "gen_constants = gen_constants[gen_constants['gen'].isin(fp_gen_map.values.ravel())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(regression_df=regression_df, well_fp_map=well_fp_map, fp_gen_map=fp_gen_map, op_cond=operating_conditions,\n",
    "              fp_constants=fp_constants, gen_constants=gen_constants, date_numeric_pred=dt2num(datetime.now())):\n",
    "    # make well regression data\n",
    "    well_df = regression_df.copy()[['well', 'date_numeric', 'whp', 'mf']]\n",
    "    well_df['well_id'], unique_wells = well_df['well'].factorize()\n",
    "    well_df = well_df.drop('well', 1)\n",
    "    well_df['well_id'] += 1\n",
    "    unique_wells_dict = {k: v+1 for v, k in enumerate(unique_wells)}\n",
    "\n",
    "    # set up current-date well conditions for predictions\n",
    "    op_df = op_cond.copy().rename(columns={'whp': 'whp_pred'})\n",
    "    op_df['well_id'] = op_df['well'].replace(unique_wells_dict)\n",
    "    op_df = op_df.sort_values('well_id').drop(['well', 'well_id'], 1)\n",
    "\n",
    "    # set up data for flash plant\n",
    "    fp_df = fp_constants.copy()\n",
    "    fp_df['fp_id'], unique_fps = fp_df['fp'].factorize()\n",
    "    fp_df = fp_df.drop('fp', 1)\n",
    "    fp_df['fp_id'] += 1\n",
    "    unique_fps_dict = {k: v+1 for v, k in enumerate(unique_fps)}\n",
    "\n",
    "    # each fp draws from which wells: {fp: [wells]}\n",
    "    well_map_df = well_fp_map.copy()\n",
    "    well_map_df['fp_id'] = well_map_df['fp'].replace(unique_fps_dict)\n",
    "    well_map_df['well_id'] = well_map_df['well'].replace(unique_wells_dict)\n",
    "    well_map_df = well_map_df.groupby('fp_id')['well_id'].apply(list).to_frame()\n",
    "    well_map_well_id = well_map_df['well_id']\n",
    "    well_map_dict = well_map_df.drop('well_id', 1).to_dict('list')\n",
    "    well_map_dict['n_fp_inflows'] = [len(x) for x in well_map_well_id]\n",
    "    # use ones to avoid JAGS indexing trouble if no inflows (extras ignored with n_inflows)\n",
    "    well_map_dict['well_fp_map'] = np.ones(\n",
    "        (len(well_map_well_id), max(well_map_dict['n_fp_inflows'], default=0)), int)\n",
    "    for i, inflows in enumerate(well_map_well_id):\n",
    "        well_map_dict['well_fp_map'][i, :well_map_dict['n_fp_inflows'][i]] = inflows\n",
    "\n",
    "    # set up data for generators\n",
    "    gen_df = gen_constants.copy()[['gen', 'factor']]\n",
    "    gen_df['gen_id'], unique_gens = gen_df['gen'].factorize()\n",
    "    gen_df = gen_df.drop('gen', 1)\n",
    "    gen_df['gen_id'] += 1\n",
    "    unique_gens_dict = {k: v+1 for v, k in enumerate(unique_gens)}\n",
    "\n",
    "    # each gen draws from FPs\n",
    "    gen_map_df = fp_gen_map.copy()\n",
    "    gen_map_df.replace(unique_gens_dict, inplace=True)\n",
    "    gen_map_df.replace(unique_fps_dict, inplace=True)\n",
    "    gen_maps = [gen_map_df[['fp', k]].groupby(k)['fp'].apply(list).to_frame().rename(columns={'fp': f'{k}'})\n",
    "                for k in gen_map_df.columns[1:]]\n",
    "    gen_maps = pd.concat(gen_maps, axis=1)\n",
    "    for name, column in gen_maps.iteritems():\n",
    "        gen_maps[f'n_{name}_inflows'] = [np.sum(~np.isnan(x)) for x in column]\n",
    "    gen_map_dict = {}\n",
    "    for k in ['gen_' + p for p in ['ip', 'lp', 'w']]:\n",
    "        gen_map_dict[f'fp_{k}_map'] = np.ones(\n",
    "            (len(gen_maps), max(1, max(gen_maps[f'n_{k}_inflows']))), int)\n",
    "        for i, inflows in enumerate(gen_maps[f'{k}'].values):\n",
    "            gen_map_dict[f'fp_{k}_map'][i, :gen_maps.iloc[i][f'n_{k}_inflows']] = inflows\n",
    "        gen_map_dict.update(\n",
    "            {f'n_{k}_inflows': gen_maps[f'n_{k}_inflows'].tolist()})\n",
    "    print(gen_map_dict)\n",
    "    # collate data into one dictionary and add naming metadata\n",
    "    data = {k: v for d in [e.to_dict('list')\n",
    "                           for e in [well_df, op_df, fp_df, gen_df]] + [well_map_dict, gen_map_dict]\n",
    "            for k, v in d.items()}\n",
    "    data.update({'n_data': len(well_df), 'n_wells': len(unique_wells),\n",
    "                 'n_fps': len(unique_fps), 'n_gens': len(unique_gens),\n",
    "                 'today_numeric': date_numeric_pred})\n",
    "    metadata = {'unique_wells': list(unique_wells), 'unique_fps': list(\n",
    "        unique_fps), 'unique_gens': list(unique_gens)}\n",
    "    return data, metadata\n",
    "\n",
    "\n",
    "_ = make_data()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code = '''\n",
    "model {\n",
    "  # fit individual regressions to wells\n",
    "  for (i in 1:n_data) {\n",
    "    mu[i] <- Intercept[well_id[i]] + beta_whp[well_id[i]] * whp[i] + beta_date_numeric[well_id[i]] * date_numeric[i]\n",
    "    mf[i] ~ dnorm(mu[i], tau[well_id[i]])\n",
    "  }\n",
    "  \n",
    "  # HIERARCHICAL\n",
    "  for (j in 1:n_wells) {\n",
    "    Intercept[j] ~ dnorm(mu_Intercept, tau_Intercept)\n",
    "    beta_whp[j] ~ dnorm(mu_beta_whp, tau_beta_whp)\n",
    "    beta_date_numeric[j] ~ dnorm(mu_date_numeric, tau_date_numeric)\n",
    "    tau[j] ~ dgamma(1e-8, 1e-8)\n",
    "  }\n",
    "  \n",
    "  # set hyperparameters\n",
    "  mu_Intercept ~ dnorm(0, 1e-8)\n",
    "  mu_beta_whp ~ dnorm(0, 1e-8)\n",
    "  mu_date_numeric ~ dnorm(0, 1e-8)\n",
    "  tau_Intercept ~ dgamma(1e-8, 1e-8)\n",
    "  tau_beta_whp ~ dgamma(1e-8, 1e-8)\n",
    "  tau_date_numeric ~ dgamma(1e-8, 1e-8)\n",
    "  \n",
    "  # ... NOT... HIERARCHICAL?\n",
    "  #for (j in 1:n_wells) {\n",
    "  #  Intercept[j] ~ dnorm(0, 1e-8)\n",
    "  #  beta_whp[j] ~ dnorm(0, 1e-8)\n",
    "  #  beta_date_numeric[j] ~ dnorm(0, 1e-8)\n",
    "  #}\n",
    "  \n",
    "  # make predictions\n",
    "  for (i in 1:n_wells) {\n",
    "    well_mu[i] <- Intercept[i] + beta_whp[i] * whp_pred[i] + beta_date_numeric[i] * today_numeric\n",
    "    well_mf[i] <- well_mu[i]\n",
    "  }\n",
    "  \n",
    "  # estimate steam at FPs using weighted sums\n",
    "  for (k in 1:n_fps) {\n",
    "    fp_mf[k] <- sum(well_mf[well_fp_map[k, 1:n_fp_inflows[k]]])\n",
    "    denom[k] <- ifelse(fp_mf[k]!=0, fp_mf[k], 1)\n",
    "    unnormed[k] <- sum(well_mf[well_fp_map[k, 1:n_fp_inflows[k]]] * h[well_fp_map[k, 1:n_fp_inflows[k]]])\n",
    "    fp_h[k] <- unnormed[k] / denom[k]\n",
    "    #fp_h[k] <- sum(well_mf[well_fp_map[k, 1:n_fp_inflows[k]]] * h[well_fp_map[k, 1:n_fp_inflows[k]]]) / max(fp_mf[k], 1e-4)\n",
    "    fp_ip_sf[k] <- (fp_h[k] - hf_ip[k]) / hfg_ip[k] * fp_mf[k]\n",
    "    fp_lp_sf[k] <- (hf_ip[k] - hf_lp[k]) / hfg_lp[k] * (fp_mf[k] - fp_ip_sf[k])\n",
    "    fp_sf[k] <- fp_ip_sf[k] + fp_lp_sf[k]\n",
    "    fp_wf[k] <- fp_mf[k] - fp_sf[k]\n",
    "  }\n",
    "  \n",
    "  # estimate power output\n",
    "  for (l in 1:n_gens) {\n",
    "    gen_ip_sf[l] <- sum(fp_ip_sf[fp_gen_ip_map[l, 1:n_gen_ip_inflows[l]]])\n",
    "    gen_lp_sf[l] <-sum(fp_lp_sf[fp_gen_lp_map[l, 1:n_gen_lp_inflows[l]]])\n",
    "    gen_wf[l] <- sum(fp_wf[fp_gen_w_map[l, 1:max(n_gen_w_inflows[l], 1)]])\n",
    "    gen_f[l] <- gen_ip_sf[l] + gen_lp_sf[l] + gen_wf[l]\n",
    "    gen_pw[l] <- gen_f[l] / factor[l]\n",
    "  }\n",
    "  pw <- sum(gen_pw)\n",
    "}\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# pyjags.load_module('glm')\n",
    "n_chains = 1\n",
    "burn_in = 1000\n",
    "myvars = ['well_mf', 'fp_mf', 'fp_h', 'fp_sf', 'gen_pw']\n",
    "\n",
    "data, metadata = make_data()\n",
    "model_fp = MyModel(code, data=data, chains=n_chains)\n",
    "model_fp.sample(burn_in)\n",
    "samples = model_fp.sample(5000, myvars)\n",
    "# samples = {k: pd.DataFrame(v.squeeze().T) for k, v in samples.items()}\n",
    "for i, (k, v) in enumerate(samples.items()):\n",
    "    samples[k] = pd.DataFrame(v.squeeze().T)\n",
    "    legend = None\n",
    "    for names in metadata.values():\n",
    "        # sometimes works.\n",
    "        if len(samples[k].columns) == len(names):\n",
    "            samples[k].columns = names\n",
    "            legend = names\n",
    "    samples[k] = samples[k].melt(var_name='name', value_name=k)\n",
    "    samples[k].legend = legend\n",
    "    samples[k].value_name = k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print(\"Plotting...\")\n",
    "ncols = 3\n",
    "nrows = np.ceil(len(samples.keys())/3).astype(int)\n",
    "fig, axes = plt.subplots(nrows, ncols, figsize=[14,4*nrows])\n",
    "\n",
    "for df, ax in zip(samples.values(), fig.axes):\n",
    "    for name in df['name'].unique():\n",
    "        sns.kdeplot(central(df[df.value_name].loc[df['name']==name]), shade=True, ax=ax)\n",
    "    for facility in ['well', 'fp', 'gen']:\n",
    "        if facility in df.value_name:\n",
    "            ax.legend(metadata[f'unique_{facility}s'])\n",
    "    ax.set_xlabel(df.value_name)\n",
    "\n",
    "for ax in fig.axes:\n",
    "    ax.set_xlim(left=0)\n",
    "    ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modeltext = '''\n",
    "model {\n",
    "a <- sum(x[1:3])\n",
    "}\n",
    "'''\n",
    "data = {'x': [10, 20, 40]}\n",
    "foo = MyModel(modeltext, data, chains=1)\n",
    "samples = foo.sample(1, ['a'])\n",
    "samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression_df.to_excel('../wairakei_data/data.xlsx', 'data', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read dry wells data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if Excel file is already in memory (loading is slow)\n",
    "try:    xl2\n",
    "except: xl2 = pd.ExcelFile('../wairakei_data/short version Generation Projection 2016.xlsx')\n",
    "sheetlist = [x for x in xl2.sheet_names]\n",
    "print(\"Sheets:\", ', '.join(sheetlist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: air_raw\n",
    "except: air_raw = xl2.parse('AIR', header=3)\n",
    "air = air_raw.dropna(thresh=10)\n",
    "air.to_excel('air.xlsx')\n",
    "air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: summary_raw\n",
    "except: summary_raw = xl2.parse('SUMMARY', header=3)\n",
    "summary = summary_raw.dropna(thresh=1)\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
